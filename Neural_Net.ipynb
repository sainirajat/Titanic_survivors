{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./titanic.csv')\n",
    "test_file = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
      "       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.shape\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Name'],axis=1)\n",
    "test_file = test_file.drop(['Name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Sex', u'Age', u'SibSp',\n",
      "       u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n",
      "Index([u'PassengerId', u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch',\n",
      "       u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.columns\n",
    "print test_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print df['Sex'].isnull().values.any()\n",
    "# np_utils.to_categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.values\n",
    "# test_file = test_file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex = df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type(df['Sex'])\n",
    "# print len(Sex)\n",
    "# print type(Sex)\n",
    "# Sex = np.array(Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type(Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Sex'] = np_utils.to_categorical(Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_file['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2 = LabelEncoder()\n",
    "test_file = test_file.apply(le2.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PassengerId'],axis=1)\n",
    "test_file = test_file.drop(['PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Survived', u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Ticket',\n",
      "       u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n",
      "Index([u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Ticket', u'Fare',\n",
      "       u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.columns\n",
    "print test_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = np_utils.to_categorical(df['Sex'])\n",
    "test_file['Sex'] = np_utils.to_categorical(test_file['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values\n",
    "test_file = test_file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.    2.    0.   28.    1.    0.  523.   18.    0.    4.]\n",
      " [   1.    0.    1.   51.    1.    0.  596.  207.  768.    2.]\n",
      " [   1.    2.    1.   34.    0.    0.  669.   41.  509.    4.]\n",
      " [   1.    0.    1.   47.    1.    0.   49.  189.  742.    4.]\n",
      " [   0.    2.    0.   47.    0.    0.  472.   43.  510.    4.]]\n"
     ]
    }
   ],
   "source": [
    "print df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "[[   0.    2.    0.   28.    1.    0.  523.   18.    0.    4.]\n",
      " [   1.    0.    1.   51.    1.    0.  596.  207.  768.    2.]\n",
      " [   1.    2.    1.   34.    0.    0.  669.   41.  509.    4.]\n",
      " [   1.    0.    1.   47.    1.    0.   49.  189.  742.    4.]\n",
      " [   0.    2.    0.   47.    0.    0.  472.   43.  510.    4.]\n",
      " [   0.    2.    0.  110.    0.    0.  275.   51.  511.    3.]\n",
      " [   0.    0.    0.   69.    0.    0.   85.  186.  816.    4.]\n",
      " [   0.    2.    0.    6.    3.    1.  395.  124.  512.    4.]\n",
      " [   1.    2.    1.   35.    0.    2.  344.   74.  513.    4.]\n",
      " [   1.    1.    1.   18.    1.    0.  132.  154.  514.    2.]]\n"
     ]
    }
   ],
   "source": [
    "print type(df)\n",
    "print type(test_file)\n",
    "print df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  1.  1.  0.  0.  0.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print df[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "(668, 9) (668,)\n",
      "(223, 9) (223,)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.75*df.shape[0])\n",
    "print split\n",
    "\n",
    "train_x = df[:split,1:]\n",
    "train_y = df[:split,0]\n",
    "test_x = df[split:,1:]\n",
    "test_y = df[split:,0]\n",
    "print train_x.shape,train_y.shape\n",
    "print test_x.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 2)\n",
      "(223, 2)\n"
     ]
    }
   ],
   "source": [
    "train_yy = np_utils.to_categorical(train_y)\n",
    "test_yy = np_utils.to_categorical(test_y)\n",
    "print train_yy.shape\n",
    "print test_yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 50        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_shape=(9,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(4))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 9.7610 - acc: 0.3892 - val_loss: 9.6174 - val_acc: 0.3677\n",
      "Epoch 2/15\n",
      " - 0s - loss: 4.7302 - acc: 0.5404 - val_loss: 2.4840 - val_acc: 0.6726\n",
      "Epoch 3/15\n",
      " - 0s - loss: 2.7530 - acc: 0.6332 - val_loss: 1.7814 - val_acc: 0.6951\n",
      "Epoch 4/15\n",
      " - 0s - loss: 2.1226 - acc: 0.6467 - val_loss: 1.2746 - val_acc: 0.7220\n",
      "Epoch 5/15\n",
      " - 0s - loss: 1.8050 - acc: 0.6632 - val_loss: 1.1602 - val_acc: 0.7309\n",
      "Epoch 6/15\n",
      " - 0s - loss: 1.6417 - acc: 0.6632 - val_loss: 1.0932 - val_acc: 0.7220\n",
      "Epoch 7/15\n",
      " - 0s - loss: 1.4829 - acc: 0.6662 - val_loss: 1.1084 - val_acc: 0.7265\n",
      "Epoch 8/15\n",
      " - 0s - loss: 1.4450 - acc: 0.6632 - val_loss: 1.0230 - val_acc: 0.7265\n",
      "Epoch 9/15\n",
      " - 0s - loss: 1.4214 - acc: 0.6587 - val_loss: 1.0276 - val_acc: 0.7265\n",
      "Epoch 10/15\n",
      " - 0s - loss: 1.4150 - acc: 0.6632 - val_loss: 1.0287 - val_acc: 0.7265\n",
      "Epoch 11/15\n",
      " - 0s - loss: 1.4136 - acc: 0.6632 - val_loss: 1.0228 - val_acc: 0.7265\n",
      "Epoch 12/15\n",
      " - 0s - loss: 1.4081 - acc: 0.6632 - val_loss: 1.0324 - val_acc: 0.7265\n",
      "Epoch 13/15\n",
      " - 0s - loss: 1.4239 - acc: 0.6602 - val_loss: 1.0188 - val_acc: 0.7265\n",
      "Epoch 14/15\n",
      " - 0s - loss: 1.4120 - acc: 0.6617 - val_loss: 0.9993 - val_acc: 0.7265\n",
      "Epoch 15/15\n",
      " - 0s - loss: 1.4106 - acc: 0.6587 - val_loss: 1.0017 - val_acc: 0.7265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118164e90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_yy,batch_size=8,nb_epoch=15,verbose=2,validation_data=(test_x,test_yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will try droping out some connections(which should not be a good idea as data is small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 3)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 38\n",
      "Trainable params: 38\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(3,input_shape=(9,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 7.8472 - acc: 0.3997 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 2/15\n",
      " - 0s - loss: 8.3873 - acc: 0.3952 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 3/15\n",
      " - 0s - loss: 8.0811 - acc: 0.4057 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 4/15\n",
      " - 0s - loss: 8.1514 - acc: 0.4012 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 5/15\n",
      " - 0s - loss: 7.8937 - acc: 0.3922 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 6/15\n",
      " - 0s - loss: 7.8733 - acc: 0.3907 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 7/15\n",
      " - 0s - loss: 7.6910 - acc: 0.3997 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 8/15\n",
      " - 0s - loss: 7.8645 - acc: 0.3937 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 9/15\n",
      " - 0s - loss: 8.0008 - acc: 0.3952 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 10/15\n",
      " - 0s - loss: 7.7204 - acc: 0.3922 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 11/15\n",
      " - 0s - loss: 8.0142 - acc: 0.3937 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 12/15\n",
      " - 0s - loss: 7.6476 - acc: 0.4326 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 13/15\n",
      " - 0s - loss: 7.9722 - acc: 0.4147 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 14/15\n",
      " - 0s - loss: 7.9163 - acc: 0.4192 - val_loss: 10.1913 - val_acc: 0.3677\n",
      "Epoch 15/15\n",
      " - 0s - loss: 8.0694 - acc: 0.4117 - val_loss: 10.1913 - val_acc: 0.3677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118748bd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_x,train_yy,epochs=15,batch_size=8,verbose=2,validation_data=(test_x,test_yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thus we got 72% accuracy with our previous model on validation data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
